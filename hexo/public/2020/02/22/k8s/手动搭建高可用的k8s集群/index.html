<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Mist","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="该文档部署了最新的v1.8.2版本，实现了kube-apiserver的高可用、traefik ingress 的部署、在kubernetes上安装docker的私有仓库harbor、容器化kubernetes部分组建、使用阿里云日志服务收集日志。 部署完成后，你将理解系统各组件的交互原理，进而能快速解决实际问题，所以本文档主要适合于那些有一定kubernetes基础，想通过一步步部署的方式来学习">
<meta property="og:type" content="article">
<meta property="og:title" content="手动搭建高可用的k8s集群">
<meta property="og:url" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/index.html">
<meta property="og:site_name" content="Q&#39;s blog">
<meta property="og:description" content="该文档部署了最新的v1.8.2版本，实现了kube-apiserver的高可用、traefik ingress 的部署、在kubernetes上安装docker的私有仓库harbor、容器化kubernetes部分组建、使用阿里云日志服务收集日志。 部署完成后，你将理解系统各组件的交互原理，进而能快速解决实际问题，所以本文档主要适合于那些有一定kubernetes基础，想通过一步步部署的方式来学习">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/haproxy.png">
<meta property="og:image" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/apiserver-ha.png">
<meta property="og:image" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/1.png">
<meta property="og:image" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/nodes.png">
<meta property="og:image" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/2.png">
<meta property="article:published_time" content="2020-02-22T05:18:13.000Z">
<meta property="article:modified_time" content="2020-03-08T05:48:23.189Z">
<meta property="article:author" content="屈辉">
<meta property="article:tag" content="k8s">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/haproxy.png">

<link rel="canonical" href="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>手动搭建高可用的k8s集群 | Q's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Q's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">一些个人文档笔记</p>
  </div>

  <div class="site-nav-right"></div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">59</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类<span class="badge">20</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">115</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/Horus-K" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="屈辉">
      <meta itemprop="description" content="开心就好">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Q's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          手动搭建高可用的k8s集群
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-22 13:18:13" itemprop="dateCreated datePublished" datetime="2020-02-22T13:18:13+08:00">2020-02-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-03-08 13:48:23" itemprop="dateModified" datetime="2020-03-08T13:48:23+08:00">2020-03-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>该文档部署了最新的<code>v1.8.2</code>版本，实现了<code>kube-apiserver</code>的高可用、<code>traefik ingress</code> 的部署、在<code>kubernetes</code>上安装<code>docker</code>的私有仓库<code>harbor</code>、容器化<code>kubernetes</code>部分组建、使用阿里云日志服务收集日志。</p>
<p>部署完成后，你将理解系统各组件的交互原理，进而能快速解决实际问题，所以本文档主要适合于那些有一定<code>kubernetes</code>基础，想通过一步步部署的方式来学习和了解系统配置、运行原理的人。</p>
<p>本系列系文档适用于 <code>CentOS 7</code>、<code>Ubuntu 16.04</code> 及以上版本系统，由于启用了 <code>TLS</code> 双向认证、<code>RBAC</code> 授权等严格的安全机制，建议<strong>从头开始部署</strong>，否则可能会认证、授权等失败！</p>
<a id="more"></a>

<h1 id="1-组件版本-amp-amp-集群环境"><a href="#1-组件版本-amp-amp-集群环境" class="headerlink" title="1. 组件版本 &amp;&amp; 集群环境"></a>1. 组件版本 &amp;&amp; 集群环境</h1><h3 id="组件版本"><a href="#组件版本" class="headerlink" title="组件版本"></a>组件版本</h3><ul>
<li>Kubernetes 1.8.2(1.9.x版本也可以，只有细微的差别)</li>
<li>Docker 17.10.0-ce</li>
<li>Etcd 3.2.9</li>
<li>Flanneld</li>
<li>TLS 认证通信（所有组件，如etcd、kubernetes master 和node）</li>
<li>RBAC 授权</li>
<li>kubelet TLS Bootstrapping</li>
<li>kubedns、dashboard、heapster等插件</li>
<li>harbor，使用nfs后端存储</li>
</ul>
<h3 id="etcd-集群-amp-amp-k8s-master-机器-amp-amp-k8s-node-机器"><a href="#etcd-集群-amp-amp-k8s-master-机器-amp-amp-k8s-node-机器" class="headerlink" title="etcd 集群 &amp;&amp; k8s master 机器 &amp;&amp; k8s node 机器"></a>etcd 集群 &amp;&amp; k8s master 机器 &amp;&amp; k8s node 机器</h3><ul>
<li>master01：192.168.220.100</li>
<li>master02：192.168.220.101</li>
<li>master03/node03：192.168.220.102</li>
<li>由于机器有限，所以我们将master03 也作为node 节点，后续有新的机器增加即可</li>
<li>node01: 192.168.220.200</li>
<li>node02: 192.168.220.201</li>
</ul>
<h3 id="工作目录"><a href="#工作目录" class="headerlink" title="工作目录"></a>工作目录</h3><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta-keyword">/usr/</span>k8s<span class="meta-keyword">/bin/</span></span><br><span class="line"><span class="meta-keyword">/etc/</span>kubernetes/ssl <span class="meta">#所以机器都一样ca</span></span><br><span class="line"><span class="meta-keyword">/etc/</span>etcd/ <span class="meta">#每台机器不一样，根据ip</span></span><br></pre></td></tr></table></figure>



<h3 id="集群环境变量"><a href="#集群环境变量" class="headerlink" title="集群环境变量"></a>集群环境变量</h3><p>后面部署将会使用到的全局变量，定义如下（根据自己的机器、网络修改）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/k8s/bin/ -p</span><br><span class="line">cat &gt; /usr/k8s/bin/env.sh &lt;&lt;EOF</span><br><span class="line"><span class="comment"># TLS Bootstrapping 使用的Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x | tr -d ' ' 生成</span></span><br><span class="line">BOOTSTRAP_TOKEN=<span class="string">"f3be89d17cf7d80847f3bc8b8ea58250"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建议使用未用的网段来定义服务网段和Pod 网段</span></span><br><span class="line"><span class="comment"># 服务网段(Service CIDR)，部署前路由不可达，部署后集群内部使用IP:Port可达</span></span><br><span class="line">SERVICE_CIDR=<span class="string">"10.254.0.0/16"</span></span><br><span class="line"><span class="comment"># Pod 网段(Cluster CIDR)，部署前路由不可达，部署后路由可达(flanneld 保证)</span></span><br><span class="line">CLUSTER_CIDR=<span class="string">"172.30.0.0/16"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务端口范围(NodePort Range)</span></span><br><span class="line">NODE_PORT_RANGE=<span class="string">"30000-32766"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># etcd集群服务地址列表</span></span><br><span class="line">ETCD_ENDPOINTS=<span class="string">"https://192.168.220.100:2379,https://192.168.220.101:2379,https://192.168.220.102:2379"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># flanneld 网络配置前缀</span></span><br><span class="line">FLANNEL_ETCD_PREFIX=<span class="string">"/kubernetes/network"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubernetes 服务IP(预先分配，一般为SERVICE_CIDR中的第一个IP)</span></span><br><span class="line">CLUSTER_KUBERNETES_SVC_IP=<span class="string">"10.254.0.1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 集群 DNS 服务IP(从SERVICE_CIDR 中预先分配)</span></span><br><span class="line">CLUSTER_DNS_SVC_IP=<span class="string">"10.254.0.2"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 集群 DNS 域名</span></span><br><span class="line">CLUSTER_DNS_DOMAIN=<span class="string">"cluster.local."</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MASTER API Server 地址</span></span><br><span class="line">MASTER_URL=<span class="string">"k8s-api.virtual.local"</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>将上面变量保存为: <strong>env.sh</strong>，然后将脚本拷贝到所有机器的<code>/usr/k8s/bin</code>目录。 为方便后面迁移，我们在集群内定义一个域名用于访问<code>apiserver</code>，在每个节点的<code>/etc/hosts</code>文件中添加记录：</p>
<p><strong>192.168.220.100 k8s-api.virtual.local k8s-api</strong></p>
<p>其中<code>192.168.1.137</code>为master01 的IP，暂时使用该IP 来做apiserver 的负载地址</p>
<p>添加/usr/k8s/bin 到env中</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=/usr/k8s/bin:$PATH</span><br></pre></td></tr></table></figure>

<p>如果你使用的是阿里云的ECS 服务，强烈建议你先将上述节点的安全组配置成允许所有访问，不然在安装过程中会遇到各种访问不了的问题，待集群配置成功以后再根据需要添加安全限制。</p>
<h2 id="2-创建CA-证书和密钥"><a href="#2-创建CA-证书和密钥" class="headerlink" title="2. 创建CA 证书和密钥"></a>2. 创建CA 证书和密钥</h2><p><code>kubernetes</code> 系统各个组件需要使用<code>TLS</code>证书对通信进行加密，这里我们使用<code>CloudFlare</code>的PKI 工具集<a href="https://github.com/cloudflare/cfssl" target="_blank" rel="noopener">cfssl</a> 来生成Certificate Authority(CA) 证书和密钥文件， CA 是自签名的证书，用来签名后续创建的其他TLS 证书。</p>
<h3 id="安装-CFSSL"><a href="#安装-CFSSL" class="headerlink" title="安装 CFSSL"></a>安装 CFSSL</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">chmod +x cfssl_linux-amd64</span><br><span class="line">sudo mv cfssl_linux-amd64 /usr/k8s/bin/cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">chmod +x cfssljson_linux-amd64</span><br><span class="line">sudo mv cfssljson_linux-amd64 /usr/k8s/bin/cfssljson</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line">chmod +x cfssl-certinfo_linux-amd64</span><br><span class="line">sudo mv cfssl-certinfo_linux-amd64 /usr/k8s/bin/cfssl-certinfo</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; &#x2F;etc&#x2F;profile &lt;&lt; EOF</span><br><span class="line">export PATH&#x3D;&#x2F;usr&#x2F;k8s&#x2F;bin:$PATH</span><br><span class="line">EOF</span><br><span class="line">source &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mkdir ssl &amp;&amp; cd ssl</span><br><span class="line">cfssl print-defaults config &gt; ca-config.json</span><br><span class="line">cfssl print-defaults csr &gt; ca-csr.json</span><br></pre></td></tr></table></figure>

<h3 id="创建CA"><a href="#创建CA" class="headerlink" title="创建CA"></a>创建CA</h3><p>修改上面创建的<code>ca-config.json</code>：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"signing"</span>: &#123;</span><br><span class="line">        <span class="attr">"default"</span>: &#123;</span><br><span class="line">            <span class="attr">"expiry"</span>: <span class="string">"876000h"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"profiles"</span>: &#123;</span><br><span class="line">            <span class="attr">"kubernetes"</span>: &#123;</span><br><span class="line">                <span class="attr">"expiry"</span>: <span class="string">"876000h"</span>,</span><br><span class="line">                <span class="attr">"usages"</span>: [</span><br><span class="line">                    <span class="string">"signing"</span>,</span><br><span class="line">                    <span class="string">"key encipherment"</span>,</span><br><span class="line">                    <span class="string">"server auth"</span>,</span><br><span class="line">                    <span class="string">"client auth"</span></span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>config.json</code>：可以定义多个profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个profile；</li>
<li><code>signing</code>: 表示该证书可用于签名其它证书；生成的ca.pem 证书中<code>CA=TRUE</code>；</li>
<li><code>server auth</code>: 表示client 可以用该CA 对server 提供的证书进行校验；</li>
<li><code>client auth</code>: 表示server 可以用该CA 对client 提供的证书进行验证。</li>
</ul>
<p>修改CA 证书签名ca-csr.json：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-csr.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"CN"</span>: <span class="string">"kubernetes"</span>,</span><br><span class="line">    <span class="attr">"key"</span>: &#123;</span><br><span class="line">        <span class="attr">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">2048</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"names"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">            <span class="attr">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">            <span class="attr">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">            <span class="attr">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">            <span class="attr">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>CN</code>: <code>Common Name</code>，kube-apiserver 从证书中提取该字段作为请求的用户名(User Name)；浏览器使用该字段验证网站是否合法；</li>
<li><code>O</code>: <code>Organization</code>，kube-apiserver 从证书中提取该字段作为请求用户所属的组(Group)；</li>
</ul>
<p>生成CA 证书和私钥：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca</span><br><span class="line">ls ca*</span><br><span class="line">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem</span><br></pre></td></tr></table></figure>

<h3 id="分发证书"><a href="#分发证书" class="headerlink" title="分发证书"></a>分发证书</h3><p>将生成的CA 证书、密钥文件、配置文件拷贝到<strong>所有机器</strong>的<code>/etc/kubernetes/ssl</code>目录下面：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /etc/kubernetes/ssl</span><br><span class="line">sudo cp ca* /etc/kubernetes/ssl</span><br></pre></td></tr></table></figure>

<h2 id="3-部署高可用etcd-集群"><a href="#3-部署高可用etcd-集群" class="headerlink" title="3. 部署高可用etcd 集群"></a>3. 部署高可用etcd 集群</h2><p>kubernetes 系统使用<code>etcd</code>存储所有的数据，我们这里部署3个节点的etcd 集群，这3个节点直接复用kubernetes master的3个节点，分别命名为<code>etcd01</code>、<code>etcd02</code>、<code>etcd03</code>:</p>
<ul>
<li>etcd01：192.168.220.100</li>
<li>etcd02：192.168.220.101</li>
<li>etcd03：192.168.220.102</li>
</ul>
<h3 id="三个节点重复–-gt"><a href="#三个节点重复–-gt" class="headerlink" title="三个节点重复–&gt;"></a>三个节点重复–&gt;</h3><h3 id="定义环境变量"><a href="#定义环境变量" class="headerlink" title="定义环境变量"></a>定义环境变量</h3><p>使用到的变量如下：</p>
<p>节点1</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /usr/k8s/bin/env.sh &lt;&lt;EOF</span><br><span class="line"><span class="built_in">export</span> NODE_NAME=etcd01 <span class="comment"># 当前部署的机器名称(随便定义，只要能区分不同机器即可)</span></span><br><span class="line"><span class="built_in">export</span> NODE_IP=192.168.220.100 <span class="comment"># 当前部署的机器IP</span></span><br><span class="line"><span class="built_in">export</span> NODE_IPS=<span class="string">"192.168.220.100 192.168.220.101 192.168.220.102"</span> <span class="comment"># etcd 集群所有机器 IP</span></span><br><span class="line"><span class="comment"># etcd 集群间通信的IP和端口</span></span><br><span class="line"><span class="built_in">export</span> ETCD_NODES=etcd01=https://192.168.220.100:2380,etcd02=https://192.168.220.101:2380,etcd03=https://192.168.220.102:2380</span><br><span class="line"><span class="comment"># 导入用到的其它全局变量：ETCD_ENDPOINTS、FLANNEL_ETCD_PREFIX、CLUSTER_CIDR</span></span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">source</span> /usr/k8s/bin/env.sh</span><br></pre></td></tr></table></figure>

<p>节点2</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /usr/k8s/bin/env.sh &lt;&lt;EOF</span><br><span class="line"><span class="built_in">export</span> NODE_NAME=etcd02 <span class="comment"># 当前部署的机器名称(随便定义，只要能区分不同机器即可)</span></span><br><span class="line"><span class="built_in">export</span> NODE_IP=192.168.220.101 <span class="comment"># 当前部署的机器IP</span></span><br><span class="line"><span class="built_in">export</span> NODE_IPS=<span class="string">"192.168.220.100 192.168.220.101 192.168.220.102"</span> <span class="comment"># etcd 集群所有机器 IP</span></span><br><span class="line"><span class="comment"># etcd 集群间通信的IP和端口</span></span><br><span class="line"><span class="built_in">export</span> ETCD_NODES=etcd01=https://192.168.220.100:2380,etcd02=https://192.168.220.101:2380,etcd03=https://192.168.220.102:2380</span><br><span class="line"><span class="comment"># 导入用到的其它全局变量：ETCD_ENDPOINTS、FLANNEL_ETCD_PREFIX、CLUSTER_CIDR</span></span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">source</span> /usr/k8s/bin/env.sh</span><br></pre></td></tr></table></figure>

<p>节点3</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /usr/k8s/bin/env.sh &lt;&lt;EOF</span><br><span class="line"><span class="built_in">export</span> NODE_NAME=etcd03 <span class="comment"># 当前部署的机器名称(随便定义，只要能区分不同机器即可)</span></span><br><span class="line"><span class="built_in">export</span> NODE_IP=192.168.220.102 <span class="comment"># 当前部署的机器IP</span></span><br><span class="line"><span class="built_in">export</span> NODE_IPS=<span class="string">"192.168.220.100 192.168.220.101 192.168.220.102"</span> <span class="comment"># etcd 集群所有机器 IP</span></span><br><span class="line"><span class="comment"># etcd 集群间通信的IP和端口</span></span><br><span class="line"><span class="built_in">export</span> ETCD_NODES=etcd01=https://192.168.220.100:2380,etcd02=https://192.168.220.101:2380,etcd03=https://192.168.220.102:2380</span><br><span class="line"><span class="comment"># 导入用到的其它全局变量：ETCD_ENDPOINTS、FLANNEL_ETCD_PREFIX、CLUSTER_CIDR</span></span><br><span class="line">EOF</span><br><span class="line"><span class="built_in">source</span> /usr/k8s/bin/env.sh</span><br></pre></td></tr></table></figure>



<h3 id="下载etcd-二进制文件"><a href="#下载etcd-二进制文件" class="headerlink" title="下载etcd 二进制文件"></a>下载etcd 二进制文件</h3><p>到<a href="https://github.com/coreos/etcd/releases" target="_blank" rel="noopener">https://github.com/coreos/etcd/releases</a>页面下载最新版本的二进制文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.3.17/etcd-v3.3.17-linux-amd64.tar.gz</span><br><span class="line">tar -xvf etcd-v3.3.17-linux-amd64.tar.gz</span><br><span class="line">sudo mv etcd-v3.3.17-linux-amd64/etcd* /usr/k8s/bin/</span><br></pre></td></tr></table></figure>

<h3 id="创建TLS-密钥和证书"><a href="#创建TLS-密钥和证书" class="headerlink" title="创建TLS 密钥和证书"></a>创建TLS 密钥和证书</h3><p>为了保证通信安全，客户端(如etcdctl)与etcd 集群、etcd 集群之间的通信需要使用TLS 加密。</p>
<p>创建etcd 证书签名请求：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"CN"</span>: <span class="string">"etcd"</span>,</span><br><span class="line">  <span class="string">"hosts"</span>: [</span><br><span class="line">    <span class="string">"127.0.0.1"</span>,</span><br><span class="line">    <span class="string">"<span class="variable">$&#123;NODE_IP&#125;</span>"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"key"</span>: &#123;</span><br><span class="line">    <span class="string">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="string">"size"</span>: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"names"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="string">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="string">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">      <span class="string">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>hosts</code> 字段指定授权使用该证书的<code>etcd</code>节点IP</li>
</ul>
<p>生成<code>etcd</code>证书和私钥：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  -ca-key=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  -config=/etc/kubernetes/ssl/ca-config.json \</span><br><span class="line">  -profile=kubernetes etcd-csr.json | cfssljson -bare etcd</span><br><span class="line">  </span><br><span class="line">$ ls etcd*</span><br><span class="line">etcd.csr  etcd-csr.json  etcd-key.pem  etcd.pem</span><br><span class="line"></span><br><span class="line">sudo mkdir -p /etc/etcd/ssl</span><br><span class="line">sudo mv etcd*.pem /etc/etcd/ssl/</span><br></pre></td></tr></table></figure>

<h3 id="创建etcd-的systemd-unit-文件"><a href="#创建etcd-的systemd-unit-文件" class="headerlink" title="创建etcd 的systemd unit 文件"></a>创建etcd 的systemd unit 文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /var/lib/etcd  <span class="comment"># 必须要先创建工作目录</span></span><br><span class="line">cat &gt; etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Documentation=https://github.com/coreos</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">WorkingDirectory=/var/lib/etcd/</span><br><span class="line">ExecStart=/usr/k8s/bin/etcd \\</span><br><span class="line">  --name=<span class="variable">$&#123;NODE_NAME&#125;</span> \\</span><br><span class="line">  --cert-file=/etc/etcd/ssl/etcd.pem \\</span><br><span class="line">  --key-file=/etc/etcd/ssl/etcd-key.pem \\</span><br><span class="line">  --peer-cert-file=/etc/etcd/ssl/etcd.pem \\</span><br><span class="line">  --peer-key-file=/etc/etcd/ssl/etcd-key.pem \\</span><br><span class="line">  --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --initial-advertise-peer-urls=https://<span class="variable">$&#123;NODE_IP&#125;</span>:2380 \\</span><br><span class="line">  --listen-peer-urls=https://<span class="variable">$&#123;NODE_IP&#125;</span>:2380 \\</span><br><span class="line">  --listen-client-urls=https://<span class="variable">$&#123;NODE_IP&#125;</span>:2379,http://127.0.0.1:2379 \\</span><br><span class="line">  --advertise-client-urls=https://<span class="variable">$&#123;NODE_IP&#125;</span>:2379 \\</span><br><span class="line">  --initial-cluster-token=etcd-cluster-0 \\</span><br><span class="line">  --initial-cluster=<span class="variable">$&#123;ETCD_NODES&#125;</span> \\</span><br><span class="line">  --initial-cluster-state=new \\</span><br><span class="line">  --data-dir=/var/lib/etcd</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li>指定<code>etcd</code>的工作目录和数据目录为<code>/var/lib/etcd</code>，需要在启动服务前创建这个目录；</li>
<li>为了保证通信安全，需要指定etcd 的公私钥(cert-file和key-file)、Peers通信的公私钥和CA 证书(peer-cert-file、peer-key-file、peer-trusted-ca-file)、客户端的CA 证书(trusted-ca-file)；</li>
<li><code>--initial-cluster-state</code>值为<code>new</code>时，<code>--name</code>的参数值必须位于<code>--initial-cluster</code>列表中；</li>
</ul>
<h3 id="启动etcd-服务"><a href="#启动etcd-服务" class="headerlink" title="启动etcd 服务"></a>启动etcd 服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo mv etcd.service /etc/systemd/system/</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable etcd</span><br><span class="line">sudo systemctl start etcd</span><br><span class="line">sudo systemctl status etcd</span><br></pre></td></tr></table></figure>

<p>最先启动的etcd 进程会卡住一段时间，等待其他节点启动加入集群，在所有的etcd 节点重复上面的步骤，直到所有的机器etcd 服务都已经启动。</p>
<h3 id="验证服务"><a href="#验证服务" class="headerlink" title="验证服务"></a>验证服务</h3><p>部署完etcd 集群后，在任一etcd 节点上执行下面命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for ip in $&#123;NODE_IPS&#125;; do</span><br><span class="line">  ETCDCTL_API=3 /usr/k8s/bin/etcdctl \</span><br><span class="line">  --endpoints=https://$&#123;ip&#125;:2379  \</span><br><span class="line">  --cacert=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert=/etc/etcd/ssl/etcd.pem \</span><br><span class="line">  --key=/etc/etcd/ssl/etcd-key.pem \</span><br><span class="line">  endpoint health; done</span><br></pre></td></tr></table></figure>

<p>输出如下结果：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">https://192.168.220.100:2379 is healthy: successfully committed proposal: took = 4.719966ms</span><br><span class="line">https://192.168.220.101:2379 is healthy: successfully committed proposal: took = 5.852401ms</span><br><span class="line">https://192.168.220.102:2379 is healthy: successfully committed proposal: took = 11.755439ms</span><br></pre></td></tr></table></figure>

<p>可以看到上面的信息3个节点上的etcd 均为<strong>healthy</strong>，则表示集群服务正常。</p>
<h2 id="4-配置kubectl-命令行工具"><a href="#4-配置kubectl-命令行工具" class="headerlink" title="4. 配置kubectl 命令行工具"></a>4. 配置kubectl 命令行工具</h2><p><code>kubectl</code>默认从<code>~/.kube/config</code>配置文件中获取访问kube-apiserver 地址、证书、用户名等信息，需要正确配置该文件才能正常使用<code>kubectl</code>命令。</p>
<p>需要将下载的kubectl 二进制文件和生产的<code>~/.kube/config</code>配置文件拷贝到需要使用kubectl 命令的机器上。</p>
<blockquote>
<p>很多童鞋说这个地方不知道在哪个节点上执行，<code>kubectl</code>只是一个和<code>kube-apiserver</code>进行交互的一个命令行工具，所以你想安装到那个节点都行，master或者node任意节点都可以，比如你先在master节点上安装，这样你就可以在master节点使用<code>kubectl</code>命令行工具了，如果你想在node节点上使用(当然安装的过程肯定会用到的)，你就把master上面的<code>kubectl</code>二进制文件和<code>~/.kube/config</code>文件拷贝到对应的node节点上就行了。</p>
</blockquote>
<h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /usr/k8s/bin/env.sh &lt;&lt; EOF</span><br><span class="line">export KUBE_APISERVER="https://$&#123;MASTER_URL&#125;:6443"</span><br><span class="line">EOF</span><br><span class="line">source /usr/k8s/bin/env.sh</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意这里的<code>KUBE_APISERVER</code>地址，因为我们还没有安装<code>haproxy</code>，所以暂时需要手动指定使用<code>apiserver</code>的6443端口，等<code>haproxy</code>安装完成后就可以用使用443端口转发到6443端口去了。</p>
</blockquote>
<ul>
<li>变量KUBE_APISERVER 指定kubelet 访问的kube-apiserver 的地址，后续被写入<code>~/.kube/config</code>配置文件</li>
</ul>
<h3 id="下载kubectl"><a href="#下载kubectl" class="headerlink" title="下载kubectl"></a>下载kubectl</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.k8s.io/v1.8.2/kubernetes-client-linux-amd64.tar.gz # 如果服务器上下载不下来，可以想办法下载到本地，然后scp上去即可</span><br><span class="line">tar -xzvf kubernetes-client-linux-amd64.tar.gz</span><br><span class="line">cp kubernetes/client/bin/kube* /usr/k8s/bin/</span><br><span class="line">sudo chmod a+x /usr/k8s/bin/kube*</span><br></pre></td></tr></table></figure>

<h3 id="创建admin-证书"><a href="#创建admin-证书" class="headerlink" title="创建admin 证书"></a>创建admin 证书</h3><p>kubectl 与kube-apiserver 的安全端口通信，需要为安全通信提供TLS 证书和密钥。创建admin 证书签名请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "admin",</span><br><span class="line">  "hosts": [],</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "BeiJing",</span><br><span class="line">      "L": "BeiJing",</span><br><span class="line">      "O": "system:masters",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li>后续<code>kube-apiserver</code>使用RBAC 对客户端(如kubelet、kube-proxy、Pod)请求进行授权</li>
<li><code>kube-apiserver</code> 预定义了一些RBAC 使用的RoleBindings，如cluster-admin 将Group <code>system:masters</code>与Role <code>cluster-admin</code>绑定，该Role 授予了调用<code>kube-apiserver</code>所有API 的权限</li>
<li>O 指定了该证书的Group 为<code>system:masters</code>，kubectl使用该证书访问<code>kube-apiserver</code>时，由于证书被CA 签名，所以认证通过，同时由于证书用户组为经过预授权的<code>system:masters</code>，所以被授予访问所有API 的劝降</li>
<li>hosts 属性值为空列表</li>
</ul>
<p>生成admin 证书和私钥： #分发证书到各个服务器</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  -ca-key=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  -config=/etc/kubernetes/ssl/ca-config.json \</span><br><span class="line">  -profile=kubernetes admin-csr.json | cfssljson -bare admin</span><br><span class="line">ls admin*</span><br><span class="line">admin.csr  admin-csr.json  admin-key.pem  admin.pem</span><br><span class="line">sudo mv admin*.pem /etc/kubernetes/ssl/</span><br></pre></td></tr></table></figure>

<h3 id="创建kubectl-kubeconfig-文件"><a href="#创建kubectl-kubeconfig-文件" class="headerlink" title="创建kubectl kubeconfig 文件"></a>创建kubectl kubeconfig 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials admin \</span><br><span class="line">  --client-certificate=/etc/kubernetes/ssl/admin.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --client-key=/etc/kubernetes/ssl/admin-key.pem \</span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context kubernetes \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=admin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context kubernetes</span><br></pre></td></tr></table></figure>

<ul>
<li><code>admin.pem</code>证书O 字段值为<code>system:masters</code>，<code>kube-apiserver</code> 预定义的 RoleBinding <code>cluster-admin</code> 将 Group <code>system:masters</code> 与 Role <code>cluster-admin</code> 绑定，该 Role 授予了调用<code>kube-apiserver</code> 相关 API 的权限</li>
<li>生成的kubeconfig 被保存到 <code>~/.kube/config</code> 文件</li>
</ul>
<h3 id="分发kubeconfig-文件"><a href="#分发kubeconfig-文件" class="headerlink" title="分发kubeconfig 文件"></a>分发kubeconfig 文件</h3><p>将<code>~/.kube/config</code>文件拷贝到运行<code>kubectl</code>命令的机器的<code>~/.kube/</code>目录下去。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> ~/.kube</span><br></pre></td></tr></table></figure>



<h2 id="5-部署Flannel-网络"><a href="#5-部署Flannel-网络" class="headerlink" title="5. 部署Flannel 网络"></a>5. 部署Flannel 网络</h2><p>kubernetes 要求集群内各节点能通过Pod 网段互联互通，下面我们来使用Flannel 在所有节点上创建互联互通的Pod 网段的步骤。</p>
<blockquote>
<p>需要在所有的Node节点安装。  #所有节点（包括master）</p>
</blockquote>
<h3 id="环境变量-1"><a href="#环境变量-1" class="headerlink" title="环境变量"></a>环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /usr/k8s/bin/env.sh &lt;&lt; EOF</span><br><span class="line">export NODE_IP=192.168.220.100  # 当前部署节点的IP</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 导入全局变量</span></span><br><span class="line">source /usr/k8s/bin/env.sh</span><br></pre></td></tr></table></figure>

<h3 id="创建TLS-密钥和证书-1"><a href="#创建TLS-密钥和证书-1" class="headerlink" title="创建TLS 密钥和证书"></a>创建TLS 密钥和证书</h3><p>etcd 集群启用了双向TLS 认证，所以需要为flanneld 指定与etcd 集群通信的CA 和密钥。</p>
<p>创建flanneld 证书签名请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; flanneld-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "flanneld",</span><br><span class="line">  "hosts": [],</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "BeiJing",</span><br><span class="line">      "L": "BeiJing",</span><br><span class="line">      "O": "k8s",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>生成flanneld 证书和私钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  -ca-key=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  -config=/etc/kubernetes/ssl/ca-config.json \</span><br><span class="line">  -profile=kubernetes flanneld-csr.json | cfssljson -bare flanneld</span><br><span class="line"><span class="meta">$</span><span class="bash"> ls flanneld*</span></span><br><span class="line">flanneld.csr  flanneld-csr.json  flanneld-key.pem flanneld.pem</span><br><span class="line">sudo mkdir -p /etc/flanneld/ssl   #将证书和私钥分发到各个服务器</span><br><span class="line">sudo mv flanneld*.pem /etc/flanneld/ssl</span><br></pre></td></tr></table></figure>

<h3 id="向etcd-写入集群Pod-网段信息"><a href="#向etcd-写入集群Pod-网段信息" class="headerlink" title="向etcd 写入集群Pod 网段信息"></a>向etcd 写入集群Pod 网段信息</h3><blockquote>
<p>该步骤只需在第一次部署Flannel 网络时执行，后续在其他节点上部署Flanneld 时无需再写入该信息</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/ssl/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/ssl/flanneld-key.pem \</span><br><span class="line">  set $&#123;FLANNEL_ETCD_PREFIX&#125;/config '&#123;"Network":"'$&#123;CLUSTER_CIDR&#125;'", "SubnetLen": 24, "Backend": &#123;"Type": "vxlan"&#125;&#125;'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 得到如下反馈信息</span></span><br><span class="line">&#123;"Network":"172.30.0.0/16", "SubnetLen": 24, "Backend": &#123;"Type": "vxlan"&#125;&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>写入的 Pod 网段(${CLUSTER_CIDR}，172.30.0.0/16) 必须与<code>kube-controller-manager</code> 的 <code>--cluster-cidr</code> 选项值一致；</li>
</ul>
<h3 id="安装和配置flanneld"><a href="#安装和配置flanneld" class="headerlink" title="安装和配置flanneld"></a>安装和配置flanneld</h3><p>前往<a href="https://github.com/coreos/flannel/releases" target="_blank" rel="noopener">flanneld release</a>页面下载最新版的flanneld 二进制文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir flannel</span><br><span class="line">wget https://github.com/coreos/flannel/releases/download/v0.11.0/flannel-v0.11.0-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf flannel-v0.11.0-linux-amd64.tar.gz -C flannel</span><br><span class="line">sudo cp flannel/&#123;flanneld,mk-docker-opts.sh&#125; /usr/k8s/bin</span><br></pre></td></tr></table></figure>

<p>创建flanneld的systemd unit 文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; flanneld.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Flanneld overlay address etcd agent</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=etcd.service</span><br><span class="line">Before=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/k8s/bin/flanneld \\</span><br><span class="line">  -etcd-cafile=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  -etcd-certfile=/etc/flanneld/ssl/flanneld.pem \\</span><br><span class="line">  -etcd-keyfile=/etc/flanneld/ssl/flanneld-key.pem \\</span><br><span class="line">  -etcd-endpoints=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  -etcd-prefix=$&#123;FLANNEL_ETCD_PREFIX&#125;</span><br><span class="line">ExecStartPost=/usr/k8s/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">RequiredBy=docker.service</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>mk-docker-opts.sh</code>脚本将分配给flanneld 的Pod 子网网段信息写入到<code>/run/flannel/docker</code> 文件中，后续docker 启动时使用这个文件中的参数值为 docker0 网桥</li>
<li>flanneld 使用系统缺省路由所在的接口和其他节点通信，对于有多个网络接口的机器(内网和公网)，可以用 <code>--iface</code> 选项值指定通信接口(上面的 systemd unit 文件没指定这个选项)</li>
</ul>
<h3 id="启动flanneld"><a href="#启动flanneld" class="headerlink" title="启动flanneld"></a>启动flanneld</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo cp flanneld.service /etc/systemd/system/</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable flanneld</span><br><span class="line">sudo systemctl restart flanneld</span><br><span class="line">systemctl status flanneld</span><br></pre></td></tr></table></figure>

<h3 id="检查flanneld-服务"><a href="#检查flanneld-服务" class="headerlink" title="检查flanneld 服务"></a>检查flanneld 服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig flannel.1</span><br></pre></td></tr></table></figure>

<h3 id="检查分配给各flanneld-的Pod-网段信息"><a href="#检查分配给各flanneld-的Pod-网段信息" class="headerlink" title="检查分配给各flanneld 的Pod 网段信息"></a>检查分配给各flanneld 的Pod 网段信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看集群 Pod 网段(/16)</span></span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/ssl/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/ssl/flanneld-key.pem \</span><br><span class="line">  get $&#123;FLANNEL_ETCD_PREFIX&#125;/config</span><br><span class="line">&#123;"Network":"172.30.0.0/16", "SubnetLen": 24, "Backend": &#123;"Type": "vxlan"&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看已分配的 Pod 子网段列表(/24)</span></span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/ssl/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/ssl/flanneld-key.pem \</span><br><span class="line">  ls $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets</span><br><span class="line">/kubernetes/network/subnets/172.30.1.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.70.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.29.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.61.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.47.0-24</span><br><span class="line"></span><br><span class="line">查看某一 Pod 网段对应的 flanneld 进程监听的 IP 和网络参数</span><br><span class="line">etcdctl \</span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/ssl/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/ssl/flanneld-key.pem \</span><br><span class="line">  get $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets/172.30.1.0-24</span><br><span class="line">&#123;"PublicIP":"192.168.220.102","BackendType":"vxlan","BackendData":&#123;"VtepMAC":"66:51:aa:cc:3f:e7"&#125;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="确保各节点间Pod-网段能互联互通"><a href="#确保各节点间Pod-网段能互联互通" class="headerlink" title="确保各节点间Pod 网段能互联互通"></a>确保各节点间Pod 网段能互联互通</h3><p>在各个节点部署完Flanneld 后，查看已分配的Pod 子网段列表：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> etcdctl \</span></span><br><span class="line">  --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line">  --ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert-file=/etc/flanneld/ssl/flanneld.pem \</span><br><span class="line">  --key-file=/etc/flanneld/ssl/flanneld-key.pem \</span><br><span class="line">  ls $&#123;FLANNEL_ETCD_PREFIX&#125;/subnets</span><br><span class="line">  </span><br><span class="line">/kubernetes/network/subnets/172.30.47.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.1.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.70.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.29.0-24</span><br><span class="line">/kubernetes/network/subnets/172.30.61.0-24</span><br></pre></td></tr></table></figure>

<p>当前五个节点分配的 Pod 网段分别是：</p>
<ul>
<li>mster1 172.30.61.0</li>
<li>master2 172.30.47.0</li>
<li>master3 172.30.1.0</li>
<li>node1 172.30.70.0</li>
<li>node2 172.30.29.0</li>
</ul>
<h2 id="6-部署master-节点"><a href="#6-部署master-节点" class="headerlink" title="6. 部署master 节点"></a>6. 部署master 节点</h2><p>kubernetes master 节点包含的组件有：</p>
<ul>
<li>kube-apiserver</li>
<li>kube-scheduler</li>
<li>kube-controller-manager</li>
</ul>
<p>目前这3个组件需要部署到同一台机器上：（后面再部署高可用的master）</p>
<ul>
<li><code>kube-scheduler</code>、<code>kube-controller-manager</code> 和 <code>kube-apiserver</code> 三者的功能紧密相关；</li>
<li>同时只能有一个 <code>kube-scheduler</code>、<code>kube-controller-manager</code> 进程处于工作状态，如果运行多个，则需要通过选举产生一个 leader；</li>
</ul>
<p>master 节点与node 节点上的Pods 通过Pod 网络通信，所以需要在master 节点上部署Flannel 网络。</p>
<h3 id="环境变量-2"><a href="#环境变量-2" class="headerlink" title="环境变量"></a>环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> NODE_IP=192.168.1.137  <span class="comment"># 当前部署的master 机器IP</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">source</span> /usr/k8s/bin/env.sh</span></span><br></pre></td></tr></table></figure>

<h3 id="下载最新版本的二进制文件"><a href="#下载最新版本的二进制文件" class="headerlink" title="下载最新版本的二进制文件"></a>下载最新版本的二进制文件</h3><p>在<a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.8.md#server-binaries" target="_blank" rel="noopener">kubernetes changelog</a> 页面下载最新版本的文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.k8s.io/v1.8.9/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf kubernetes-server-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<p>将二进制文件拷贝到<code>/usr/k8s/bin</code>目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp -r server/bin/&#123;kube-apiserver,kube-controller-manager,kube-scheduler&#125; /usr/k8s/bin/</span><br></pre></td></tr></table></figure>

<h3 id="创建kubernetes-证书-以下master机器都要做"><a href="#创建kubernetes-证书-以下master机器都要做" class="headerlink" title="创建kubernetes 证书 #以下master机器都要做"></a>创建kubernetes 证书 #以下master机器都要做</h3><p>创建kubernetes 证书签名请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubernetes-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kubernetes",</span><br><span class="line">  "hosts": [</span><br><span class="line">    "127.0.0.1",</span><br><span class="line">    "$&#123;NODE_IP&#125;",</span><br><span class="line">    "$&#123;MASTER_URL&#125;",</span><br><span class="line">    "$&#123;CLUSTER_KUBERNETES_SVC_IP&#125;",</span><br><span class="line">    "kubernetes",</span><br><span class="line">    "kubernetes.default",</span><br><span class="line">    "kubernetes.default.svc",</span><br><span class="line">    "kubernetes.default.svc.cluster",</span><br><span class="line">    "kubernetes.default.svc.cluster.local"</span><br><span class="line">  ],</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "BeiJing",</span><br><span class="line">      "L": "BeiJing",</span><br><span class="line">      "O": "k8s",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li>如果 hosts 字段不为空则需要指定授权使用该证书的 <strong>IP 或域名列表</strong>，所以上面分别指定了当前部署的 master 节点主机 IP 以及apiserver 负载的内部域名</li>
<li>还需要添加 kube-apiserver 注册的名为 <code>kubernetes</code> 的服务 IP (Service Cluster IP)，一般是 kube-apiserver <code>--service-cluster-ip-range</code> 选项值指定的网段的<strong>第一个IP</strong>，如 “10.254.0.1”</li>
</ul>
<p>生成kubernetes 证书和私钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  -ca-key=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  -config=/etc/kubernetes/ssl/ca-config.json \</span><br><span class="line">  -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes</span><br><span class="line">  </span><br><span class="line"><span class="meta">$</span><span class="bash"> ls kubernetes*</span></span><br><span class="line">kubernetes.csr  kubernetes-csr.json  kubernetes-key.pem  kubernetes.pem</span><br><span class="line"></span><br><span class="line">sudo mkdir -p /etc/kubernetes/ssl/</span><br><span class="line">sudo mv kubernetes*.pem /etc/kubernetes/ssl/</span><br></pre></td></tr></table></figure>

<h3 id="6-1-配置和启动kube-apiserver"><a href="#6-1-配置和启动kube-apiserver" class="headerlink" title="6.1 配置和启动kube-apiserver"></a>6.1 配置和启动kube-apiserver</h3><h4 id="创建kube-apiserver-使用的客户端token-文件"><a href="#创建kube-apiserver-使用的客户端token-文件" class="headerlink" title="创建kube-apiserver 使用的客户端token 文件"></a>创建kube-apiserver 使用的客户端token 文件</h4><p>kubelet 首次启动时向kube-apiserver 发送TLS Bootstrapping 请求，kube-apiserver 验证请求中的token 是否与它配置的token.csv 一致，如果一致则自动为kubelet 生成证书和密钥。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 导入的 environment.sh 文件定义了 BOOTSTRAP_TOKEN 变量</span></span><br><span class="line">cat &gt; token.csv &lt;&lt;EOF</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,<span class="string">"system:kubelet-bootstrap"</span></span></span><br><span class="line">EOF</span><br><span class="line">sudo mv token.csv /etc/kubernetes/</span><br></pre></td></tr></table></figure>

<h4 id="创建kube-apiserver-的systemd-unit文件"><a href="#创建kube-apiserver-的systemd-unit文件" class="headerlink" title="创建kube-apiserver 的systemd unit文件"></a>创建kube-apiserver 的systemd unit文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">cat  &gt; kube-apiserver.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/k8s/bin/kube-apiserver \\</span><br><span class="line">  --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\</span><br><span class="line">  --advertise-address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --bind-address=0.0.0.0 \\</span><br><span class="line">  --insecure-bind-address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --authorization-mode=Node,RBAC \\</span><br><span class="line">  --runtime-config=rbac.authorization.k8s.io/v1alpha1 \\</span><br><span class="line">  --kubelet-https=true \\</span><br><span class="line">  --experimental-bootstrap-token-auth \\</span><br><span class="line">  --token-auth-file=/etc/kubernetes/token.csv \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --service-node-port-range=$&#123;NODE_PORT_RANGE&#125; \\</span><br><span class="line">  --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem \\</span><br><span class="line">  --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \\</span><br><span class="line">  --client-ca-file=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">  --etcd-cafile=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem \\</span><br><span class="line">  --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem \\</span><br><span class="line">  --etcd-servers=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  --enable-swagger-ui=true \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --apiserver-count=2 \\</span><br><span class="line">  --audit-log-maxage=30 \\</span><br><span class="line">  --audit-log-maxbackup=3 \\</span><br><span class="line">  --audit-log-maxsize=100 \\</span><br><span class="line">  --audit-log-path=/var/lib/audit.log \\</span><br><span class="line">  --audit-policy-file=/etc/kubernetes/audit-policy.yaml \\</span><br><span class="line">  --event-ttl=1h \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=6</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li>如果你安装的是<strong>1.9.x</strong>版本的，一定要记住上面的参数<code>experimental-bootstrap-token-auth</code>，需要替换成<code>enable-bootstrap-token-auth</code>，因为这个参数在<strong>1.9.x</strong>里面已经废弃掉了</li>
<li>kube-apiserver 1.6 版本开始使用 etcd v3 API 和存储格式</li>
<li><code>--authorization-mode=RBAC</code> 指定在安全端口使用RBAC 授权模式，拒绝未通过授权的请求</li>
<li>kube-scheduler、kube-controller-manager 一般和 kube-apiserver 部署在同一台机器上，它们使用<strong>非安全端口</strong>和 kube-apiserver通信</li>
<li>kubelet、kube-proxy、kubectl 部署在其它 Node 节点上，如果通过<strong>安全端口</strong>访问 kube-apiserver，则必须先通过 TLS 证书认证，再通过 RBAC 授权</li>
<li>kube-proxy、kubectl 通过使用证书里指定相关的 User、Group 来达到通过 RBAC 授权的目的</li>
<li>如果使用了 kubelet TLS Boostrap 机制，则不能再指定 <code>--kubelet-certificate-authority</code>、<code>--kubelet-client-certificate</code> 和 <code>--kubelet-client-key</code> 选项，否则后续 kube-apiserver 校验 kubelet 证书时出现 ”x509: certificate signed by unknown authority“ 错误</li>
<li><code>--admission-control</code> 值必须包含 <code>ServiceAccount</code>，否则部署集群插件时会失败</li>
<li><code>--bind-address</code> 不能为 <code>127.0.0.1</code></li>
<li><code>--service-cluster-ip-range</code> 指定 Service Cluster IP 地址段，该地址段不能路由可达</li>
<li><code>--service-node-port-range=${NODE_PORT_RANGE}</code> 指定 NodePort 的端口范围</li>
<li>缺省情况下 kubernetes 对象保存在<code>etcd/registry</code> 路径下，可以通过 <code>--etcd-prefix</code> 参数进行调整</li>
<li>kube-apiserver 1.8版本后需要在<code>--authorization-mode</code>参数中添加<code>Node</code>，即：<code>--authorization-mode=Node,RBAC</code>，否则Node 节点无法注册</li>
<li>注意要开启审查日志功能，指定<code>--audit-log-path</code>参数是不够的，这只是指定了日志的路径，还需要指定一个审查日志策略文件：<code>--audit-policy-file</code>，我们也可以使用日志收集工具收集相关的日志进行分析。</li>
</ul>
<p>审查日志策略文件内容如下：（<strong>/etc/kubernetes/audit-policy.yaml</strong>）</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&gt;</span> <span class="string">/etc/kubernetes/audit-policy.yaml</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">audit.k8s.io/v1beta1</span> <span class="comment"># This is required.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Policy</span></span><br><span class="line"><span class="comment"># Don't generate audit events for all requests in RequestReceived stage.</span></span><br><span class="line"><span class="attr">omitStages:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"RequestReceived"</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="comment"># Log pod changes at RequestResponse level</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">RequestResponse</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span></span><br><span class="line">      <span class="comment"># Resource "pods" doesn't match requests to any subresource of pods,</span></span><br><span class="line">      <span class="comment"># which is consistent with the RBAC policy.</span></span><br><span class="line">      <span class="attr">resources:</span> <span class="string">["pods"]</span></span><br><span class="line">  <span class="comment"># Log "pods/log", "pods/status" at Metadata level</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span></span><br><span class="line">      <span class="attr">resources:</span> <span class="string">["pods/log",</span> <span class="string">"pods/status"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Don't log requests to a configmap called "controller-leader"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span></span><br><span class="line">      <span class="attr">resources:</span> <span class="string">["configmaps"]</span></span><br><span class="line">      <span class="attr">resourceNames:</span> <span class="string">["controller-leader"]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Don't log watch requests by the "system:kube-proxy" on endpoints or services</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">users:</span> <span class="string">["system:kube-proxy"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["watch"]</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span> <span class="comment"># core API group</span></span><br><span class="line">      <span class="attr">resources:</span> <span class="string">["endpoints",</span> <span class="string">"services"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Don't log authenticated requests to certain non-resource URL paths.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">None</span></span><br><span class="line">    <span class="attr">userGroups:</span> <span class="string">["system:authenticated"]</span></span><br><span class="line">    <span class="attr">nonResourceURLs:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"/api*"</span> <span class="comment"># Wildcard matching.</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"/version"</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Log the request body of configmap changes in kube-system.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Request</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span> <span class="comment"># core API group</span></span><br><span class="line">      <span class="attr">resources:</span> <span class="string">["configmaps"]</span></span><br><span class="line">    <span class="comment"># This rule only applies to resources in the "kube-system" namespace.</span></span><br><span class="line">    <span class="comment"># The empty string "" can be used to select non-namespaced resources.</span></span><br><span class="line">    <span class="attr">namespaces:</span> <span class="string">["kube-system"]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Log configmap and secret changes in all other namespaces at the Metadata level.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span> <span class="comment"># core API group</span></span><br><span class="line">      <span class="attr">resources:</span> <span class="string">["secrets",</span> <span class="string">"configmaps"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Log all other resources in core and extensions at the Request level.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Request</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">""</span> <span class="comment"># core API group</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">group:</span> <span class="string">"extensions"</span> <span class="comment"># Version of group should NOT be included.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># A catch-all rule to log all other requests at the Metadata level.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">level:</span> <span class="string">Metadata</span></span><br><span class="line">    <span class="comment"># Long-running requests like watches that fall under this rule will not</span></span><br><span class="line">    <span class="comment"># generate an audit event in RequestReceived.</span></span><br><span class="line">    <span class="attr">omitStages:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">"RequestReceived"</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>审查日志的相关配置可以查看文档了解：<a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/debug-application-cluster/audit/</a></p>
<h4 id="启动kube-apiserver"><a href="#启动kube-apiserver" class="headerlink" title="启动kube-apiserver"></a>启动kube-apiserver</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo cp kube-apiserver.service /etc/systemd/system/</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable kube-apiserver</span><br><span class="line">sudo systemctl start kube-apiserver</span><br><span class="line">sudo systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>

<h3 id="6-2-配置和启动kube-controller-manager"><a href="#6-2-配置和启动kube-controller-manager" class="headerlink" title="6.2 配置和启动kube-controller-manager"></a>6.2 配置和启动kube-controller-manager</h3><h4 id="创建kube-controller-manager-的systemd-unit-文件"><a href="#创建kube-controller-manager-的systemd-unit-文件" class="headerlink" title="创建kube-controller-manager 的systemd unit 文件"></a>创建kube-controller-manager 的systemd unit 文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/k8s/bin/kube-controller-manager \\</span><br><span class="line">  --address=127.0.0.1 \\</span><br><span class="line">  --master=http://$&#123;MASTER_URL&#125;:8080 \\</span><br><span class="line">  --allocate-node-cidrs=true \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --cluster-cidr=$&#123;CLUSTER_CIDR&#125; \\</span><br><span class="line">  --cluster-name=kubernetes \\</span><br><span class="line">  --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">  --service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">  --root-ca-file=/etc/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --leader-elect=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>--address</code> 值必须为 <code>127.0.0.1</code>，因为当前 kube-apiserver 期望 scheduler 和 controller-manager 在同一台机器</li>
<li><code>--master=http://${MASTER_URL}:8080</code>：使用<code>http</code>(非安全端口)与 kube-apiserver 通信，需要下面的<code>haproxy</code>安装成功后才能去掉8080端口。</li>
<li><code>--cluster-cidr</code> 指定 Cluster 中 Pod 的 CIDR 范围，该网段在各 Node 间必须路由可达(flanneld保证)</li>
<li><code>--service-cluster-ip-range</code> 参数指定 Cluster 中 Service 的CIDR范围，该网络在各 Node 间必须路由不可达，必须和 kube-apiserver 中的参数一致</li>
<li><code>--cluster-signing-*</code> 指定的证书和私钥文件用来签名为 TLS BootStrap 创建的证书和私钥</li>
<li><code>--root-ca-file</code> 用来对 kube-apiserver 证书进行校验，<strong>指定该参数后，才会在Pod 容器的 ServiceAccount 中放置该 CA 证书文件</strong></li>
<li><code>--leader-elect=true</code> 部署多台机器组成的 master 集群时选举产生一处于工作状态的 <code>kube-controller-manager</code> 进程</li>
</ul>
<h4 id="启动kube-controller-manager"><a href="#启动kube-controller-manager" class="headerlink" title="启动kube-controller-manager"></a>启动kube-controller-manager</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo cp kube-controller-manager.service /etc/systemd/system/</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable kube-controller-manager</span><br><span class="line">sudo systemctl start kube-controller-manager</span><br><span class="line">sudo systemctl status kube-controller-manager</span><br></pre></td></tr></table></figure>

<h3 id="6-3-配置和启动kube-scheduler"><a href="#6-3-配置和启动kube-scheduler" class="headerlink" title="6.3 配置和启动kube-scheduler"></a>6.3 配置和启动kube-scheduler</h3><h4 id="创建kube-scheduler-的systemd-unit文件"><a href="#创建kube-scheduler-的systemd-unit文件" class="headerlink" title="创建kube-scheduler 的systemd unit文件"></a>创建kube-scheduler 的systemd unit文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/usr/k8s/bin/kube-scheduler \\</span><br><span class="line">  --address=127.0.0.1 \\</span><br><span class="line">  --master=http://$&#123;MASTER_URL&#125;:8080 \\</span><br><span class="line">  --leader-elect=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>--address</code> 值必须为 <code>127.0.0.1</code>，因为当前 kube-apiserver 期望 scheduler 和 controller-manager 在同一台机器</li>
<li><code>--master=http://${MASTER_URL}:8080</code>：使用<code>http</code>(非安全端口)与 kube-apiserver 通信，需要下面的<code>haproxy</code>启动成功后才能去掉8080端口</li>
<li><code>--leader-elect=true</code> 部署多台机器组成的 master 集群时选举产生一处于工作状态的 <code>kube-controller-manager</code> 进程</li>
</ul>
<h4 id="启动kube-scheduler"><a href="#启动kube-scheduler" class="headerlink" title="启动kube-scheduler"></a>启动kube-scheduler</h4><p>k8s-api.virtual.local 加hosts解析</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo cp kube-scheduler.service /etc/systemd/system/</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable kube-scheduler</span><br><span class="line">sudo systemctl start kube-scheduler</span><br><span class="line">sudo systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>

<h3 id="6-4-验证master-节点"><a href="#6-4-验证master-节点" class="headerlink" title="6.4 验证master 节点"></a>6.4 验证master 节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get componentstatuses</span><br><span class="line">NAME                 STATUS    MESSAGE              ERROR</span><br><span class="line">scheduler            Healthy   ok</span><br><span class="line">controller-manager   Healthy   ok</span><br><span class="line">etcd-1               Healthy   &#123;"health": "true"&#125;</span><br><span class="line">etcd-2               Healthy   &#123;"health": "true"&#125;</span><br><span class="line">etcd-0               Healthy   &#123;"health": "true"&#125;</span><br></pre></td></tr></table></figure>

<h2 id="7-kube-apiserver-高可用"><a href="#7-kube-apiserver-高可用" class="headerlink" title="7. kube-apiserver 高可用"></a>7. kube-apiserver 高可用</h2><p>按照上面的方式在<code>master02</code>与<code>master03</code>机器上安装<code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>，但是现在我们还是手动指定访问的6443和8080端口的，因为我们的域名<code>k8s-api.virtual.local</code>对应的<code>master01</code>节点直接通过http 和https 还不能访问，这里我们使用<code>haproxy</code> 来代替请求。</p>
<blockquote>
<p>明白什么意思吗？就是我们需要将http默认的80端口请求转发到<code>apiserver</code>的8080端口，将https默认的443端口请求转发到<code>apiserver</code>的6443端口，所以我们这里使用<code>haproxy</code>来做请求转发。</p>
</blockquote>
<h3 id="安装haproxy"><a href="#安装haproxy" class="headerlink" title="安装haproxy"></a>安装haproxy</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">http://www.haproxy.org/download/2.1/src/haproxy-2.1.3.tar.gz #编译安装</span><br><span class="line">yum install gcc gcc-c++ glibc glibc-devel pcre pcre-devel openssl openssl-devel systemd-devel net-tools vim iotop bc zip unzip zlib-devel lrzsz tree screen lsof tcpdump wget ntpdate</span><br><span class="line">make TARGET=linux-glibc   USE_OPENSSL=1 USE_SYSTEMD=1 USE_PCRE=1  USE_ZLIB=1  &amp;&amp; make install</span><br><span class="line"></span><br><span class="line">yum install -y haproxy</span><br></pre></td></tr></table></figure>

<h3 id="配置haproxy"><a href="#配置haproxy" class="headerlink" title="配置haproxy"></a>配置haproxy</h3><p>由于集群内部有的组建是通过非安全端口访问apiserver 的，有的是通过安全端口访问apiserver 的，所以我们要配置http 和https 两种代理方式，配置文件 <code>/etc/haproxy/haproxy.cfg</code>：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">listen stats</span><br><span class="line">  bind    *:<span class="number">9000</span></span><br><span class="line">  mode    http</span><br><span class="line">  stats   enable</span><br><span class="line">  stats   hide-version</span><br><span class="line">  stats   uri       /stats</span><br><span class="line">  stats   <span class="built_in">ref</span>resh   <span class="number">30</span>s</span><br><span class="line">  stats   realm     Haproxy\ Statistics</span><br><span class="line">  stats   auth      Admin:Password</span><br><span class="line"></span><br><span class="line">frontend k8s-api</span><br><span class="line">    bind <span class="number">192.168</span><span class="number">.220</span><span class="number">.224</span>:<span class="number">443</span></span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    tcp-request inspect-delay <span class="number">5</span>s</span><br><span class="line">    tcp-request content accept <span class="keyword">if</span> &#123; req.ssl_hello_type <span class="number">1</span> &#125;</span><br><span class="line">    default_backend k8s-api</span><br><span class="line"></span><br><span class="line">backend k8s-api</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    option tcp-check</span><br><span class="line">    balance roundrobin</span><br><span class="line">    <span class="keyword">default</span>-server <span class="built_in">int</span>er <span class="number">10</span>s downinter <span class="number">5</span>s rise <span class="number">2</span> fall <span class="number">2</span> slowstart <span class="number">60</span>s maxconn <span class="number">250</span> maxqueue <span class="number">256</span> weight <span class="number">100</span></span><br><span class="line">    server k8s-api<span class="number">-1</span> <span class="number">192.168</span><span class="number">.220</span><span class="number">.100</span>:<span class="number">6443</span> check</span><br><span class="line">    server k8s-api<span class="number">-2</span> <span class="number">192.168</span><span class="number">.220</span><span class="number">.101</span>:<span class="number">6443</span> check</span><br><span class="line"></span><br><span class="line">frontend k8s-http-api</span><br><span class="line">    bind <span class="number">192.168</span><span class="number">.220</span><span class="number">.224</span>:<span class="number">80</span></span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    default_backend k8s-http-api</span><br><span class="line"></span><br><span class="line">backend k8s-http-api</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    option tcp-check</span><br><span class="line">    balance roundrobin</span><br><span class="line">    <span class="keyword">default</span>-server <span class="built_in">int</span>er <span class="number">10</span>s downinter <span class="number">5</span>s rise <span class="number">2</span> fall <span class="number">2</span> slowstart <span class="number">60</span>s maxconn <span class="number">250</span> maxqueue <span class="number">256</span> weight <span class="number">100</span></span><br><span class="line">    server k8s-http-api<span class="number">-1</span> <span class="number">192.168</span><span class="number">.220</span><span class="number">.100</span>:<span class="number">8080</span> check</span><br><span class="line">    server k8s-http-api<span class="number">-2</span> <span class="number">192.168</span><span class="number">.220</span><span class="number">.101</span>:<span class="number">8080</span> check</span><br></pre></td></tr></table></figure>

<p>通过上面的配置文件我们可以看出通过<code>https</code>的访问将请求转发给apiserver 的6443端口了，http的请求转发到了apiserver 的8080端口。</p>
<p>修改内核参数： /etc/sysctl.conf</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/sysctl.conf &lt;&lt; <span class="literal">EOF</span></span><br><span class="line">net.ipv4.ip_forward = <span class="number">1</span></span><br><span class="line">net.ipv4.ip_nonlocal_bind=<span class="number">1</span></span><br><span class="line"><span class="literal">EOF</span></span><br></pre></td></tr></table></figure>

<p>保存结果，使结果生效</p>
<p>sysctl -p</p>
<h3 id="启动haproxy"><a href="#启动haproxy" class="headerlink" title="启动haproxy"></a>启动haproxy</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start haproxy</span><br><span class="line">sudo systemctl enable haproxy</span><br><span class="line">sudo systemctl status haproxy</span><br></pre></td></tr></table></figure>

<p>然后我们可以通过上面<code>9000</code>端口监控我们的<code>haproxy</code>的运行状态(<code>192.168.220.100:9000/stats</code>):</p>
<p><img src="/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/haproxy.png" alt="haproxy stats"></p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>上面我们的<code>haproxy</code>的确可以代理我们的两个master 上的apiserver 了，但是还不是高可用的，如果master01 这个节点down 掉了，那么我们haproxy 就不能正常提供服务了。这里我们可以使用两种方法来实现高可用</p>
<h4 id="方式1：使用阿里云SLB"><a href="#方式1：使用阿里云SLB" class="headerlink" title="方式1：使用阿里云SLB"></a>方式1：使用阿里云SLB</h4><p>这种方式实际上是最省心的，在阿里云上建一个内网的SLB，将master01 与master02 添加到SLB 机器组中，转发80(http)和443(https)端口即可（注意下面的提示）</p>
<blockquote>
<p>注意：阿里云的负载均衡是四层TCP负责，不支持后端ECS实例既作为Real Server又作为客户端向所在的负载均衡实例发送请求。因为返回的数据包只在云服务器内部转发，不经过负载均衡，所以在后端ECS实例上去访问负载均衡的服务地址是不通的。什么意思？就是如果你要使用阿里云的SLB的话，那么你不能在<code>apiserver</code>节点上使用SLB（比如在apiserver 上安装kubectl，然后将apiserver的地址设置为SLB的负载地址使用），因为这样的话就可能造成回环了，所以简单的做法是另外用两个新的节点做<code>HA</code>实例，然后将这两个实例添加到<code>SLB</code> 机器组中。</p>
</blockquote>
<h4 id="方式2：使用keepalived"><a href="#方式2：使用keepalived" class="headerlink" title="方式2：使用keepalived"></a>方式2：使用keepalived</h4><p><code>KeepAlived</code> 是一个高可用方案，通过 VIP（即虚拟 IP）和心跳检测来实现高可用。其原理是存在一组（两台）服务器，分别赋予 Master、Backup 两个角色，默认情况下Master 会绑定VIP 到自己的网卡上，对外提供服务。Master、Backup 会在一定的时间间隔向对方发送心跳数据包来检测对方的状态，这个时间间隔一般为 2 秒钟，如果Backup 发现Master 宕机，那么Backup 会发送ARP 包到网关，把VIP 绑定到自己的网卡，此时Backup 对外提供服务，实现自动化的故障转移，当Master 恢复的时候会重新接管服务。非常类似于路由器中的虚拟路由器冗余协议（VRRP）</p>
<p>k8s-api.virtual.local hosts 改为 192.168.220.224</p>
<p>开启路由转发，这里我们定义虚拟IP为：<strong>192.168.220.224</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysctl.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加以下内容</span></span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.ipv4.ip_nonlocal_bind = 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证并生效</span></span><br><span class="line">sysctl -p</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证是否生效</span></span><br><span class="line">cat /proc/sys/net/ipv4/ip_forward</span><br><span class="line">1</span><br></pre></td></tr></table></figure>

<p>安装<code>keepalived</code>:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y keepalived</span><br></pre></td></tr></table></figure>

<p>我们这里将master01 设置为Master，master02 设置为Backup，修改配置：</p>
<p>master1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[11:51:13 root@k8s-master1 ~]$cat /etc/keepalived/keepalived.conf </span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">   &#125;</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">   vrrp_skip_check_adv_addr</span><br><span class="line"><span class="meta">   #</span><span class="bash">vrrp_strict</span></span><br><span class="line">   vrrp_garp_interval 0</span><br><span class="line">   vrrp_gna_interval 0</span><br><span class="line">   vrrp_iptables</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface ens33</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.200.224/24 dev ens33 label ens33:0</span><br><span class="line">    &#125;</span><br><span class="line">    # 使用单播通信，默认是组播通信</span><br><span class="line">    unicast_src_ip 192.168.220.100</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        192.168.220.101</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_haproxy</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>统一的方式在master02 节点上安装keepalived，修改配置，只需要将state 更改成BACKUP，priority更改成99，unicast_src_ip 与unicast_peer 地址修改即可。</p>
<p>启动keepalived:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start keepalived</span><br><span class="line">systemctl enable keepalived</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看日志</span></span><br><span class="line">journalctl -f -u keepalived</span><br></pre></td></tr></table></figure>

<p>验证虚拟IP:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用ifconfig -a 命令查看不到，要使用ip addr</span></span><br><span class="line">ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link/ether 00:16:3e:00:55:c1 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.1.137/24 brd 192.168.1.255 scope global dynamic eth0</span><br><span class="line">       valid_lft 31447746sec preferred_lft 31447746sec</span><br><span class="line">    inet 192.168.1.139/24 brd 192.168.1.255 scope global secondary eth0-vip</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>

<blockquote>
<p>到这里，我们就可以将上面的6443端口和8080端口去掉了，可以手动将<code>kubectl</code>生成的<code>config</code>文件(<code>~/.kube/config</code>)中的server 地址6443端口去掉</p>
<p>另外<code>kube-controller-manager</code>和<code>kube-scheduler</code>的<strong>–master</strong>参数中的8080端口去掉了，然后分别重启这两个组件即可。</p>
</blockquote>
<p>验证apiserver：关闭master01 节点上的kube-apiserver 进程，curl 192.168.220.224 是否正确</p>
<blockquote>
<p>master01 与master 02 节点都需要安装keepalived 和haproxy，实际上我们虚拟IP的自身检测应该是检测haproxy，脚本大家可以自行更改</p>
</blockquote>
<p><img src="/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/apiserver-ha.png" alt="kube-apiserver ha"></p>
<p>这样我们就实现了接入层apiserver 的高可用了，一个部分是多活的apiserver 服务，另一个部分是一主一备的haproxy 服务。</p>
<h3 id="kube-controller-manager-和kube-scheduler-的高可用"><a href="#kube-controller-manager-和kube-scheduler-的高可用" class="headerlink" title="kube-controller-manager 和kube-scheduler 的高可用"></a>kube-controller-manager 和kube-scheduler 的高可用</h3><p>Kubernetes 的管理层服务包括<code>kube-scheduler</code>和<code>kube-controller-manager</code>。kube-scheduler和kube-controller-manager使用一主多从的高可用方案，在<strong>同一时刻只允许一个服务</strong>处以具体的任务。Kubernetes中实现了一套简单的选主逻辑，依赖Etcd实现scheduler和controller-manager的选主功能。如果scheduler和controller-manager在启动的时候设置了<code>leader-elect</code>参数，它们在启动后会先尝试获取leader节点身份，只有在获取leader节点身份后才可以执行具体的业务逻辑。它们分别会在Etcd中创建kube-scheduler和kube-controller-manager的endpoint，endpoint的信息中记录了当前的leader节点信息，以及记录的上次更新时间。leader节点会定期更新endpoint的信息，维护自己的leader身份。每个从节点的服务都会定期检查endpoint的信息，如果endpoint的信息在时间范围内没有更新，它们会尝试更新自己为leader节点。scheduler服务以及controller-manager服务之间不会进行通信，利用Etcd的强一致性，能够保证在分布式高并发情况下leader节点的全局唯一性。整体方案如下图所示：</p>
<p><img src="/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/1.png" alt></p>
<p>当集群中的leader节点服务异常后，其它节点的服务会尝试更新自身为leader节点，当有多个节点同时更新endpoint时，由Etcd保证只有一个服务的更新请求能够成功。通过这种机制sheduler和controller-manager可以保证在leader节点宕机后其它的节点可以顺利选主，保证服务故障后快速恢复。当集群中的网络出现故障时对服务的选主影响不是很大，因为scheduler和controller-manager是依赖Etcd进行选主的，在网络故障后，可以和Etcd通信的主机依然可以按照之前的逻辑进行选主，就算集群被切分，Etcd也可以保证同一时刻只有一个节点的服务处于leader状态。</p>
<h2 id="8-部署Node-节点"><a href="#8-部署Node-节点" class="headerlink" title="8. 部署Node 节点"></a>8. 部署Node 节点</h2><p>kubernetes Node 节点包含如下组件：</p>
<ul>
<li>flanneld</li>
<li>docker</li>
<li>kubelet</li>
<li>kube-proxy</li>
</ul>
<h3 id="环境变量-3"><a href="#环境变量-3" class="headerlink" title="环境变量"></a>环境变量</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export KUBE_APISERVER="https://$&#123;MASTER_URL&#125;"  // 如果你没有安装`haproxy`的话，还是需要使用6443端口的哦</span><br><span class="line">export NODE_IP=192.168.1.170  # 当前部署的节点 IP</span><br><span class="line"></span><br><span class="line">source /usr/k8s/bin/env.sh</span><br></pre></td></tr></table></figure>

<p>按照上面的步骤安装配置好flanneld</p>
<h3 id="开启路由转发"><a href="#开启路由转发" class="headerlink" title="开启路由转发"></a>开启路由转发</h3><p>修改<code>/etc/sysctl.conf</code>文件，添加下面的规则：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line">vm.swappiness = 0</span><br><span class="line">EOF</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>

<h3 id="配置docker"><a href="#配置docker" class="headerlink" title="配置docker"></a>配置docker</h3><p>你可以用二进制或yum install 的方式来安装docker，然后修改docker 的systemd unit 文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat /usr/lib/systemd/system/docker.service  # 用systemctl status docker 命令可查看unit 文件路径</span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target firewalld.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line"><span class="meta">#</span><span class="bash"> the default is not to use systemd <span class="keyword">for</span> cgroups because the delegate issues still</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> exists and systemd currently does not support the cgroup feature <span class="built_in">set</span> required</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> containers run by docker</span></span><br><span class="line">EnvironmentFile=-/run/flannel/docker</span><br><span class="line">ExecStart=/usr/bin/dockerd --log-level=info $DOCKER_NETWORK_OPTIONS</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line"><span class="meta">#</span><span class="bash"> Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">in</span> the kernel. We recommend using cgroups to <span class="keyword">do</span> container-local accounting.</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"><span class="meta">#</span><span class="bash"> Uncomment TasksMax <span class="keyword">if</span> your systemd version supports it.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Only systemd 226 and above support this version.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">TasksMax=infinity</span></span><br><span class="line">TimeoutStartSec=0</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> delegate yes so that systemd does not reset the cgroups of docker containers</span></span><br><span class="line">Delegate=yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">kill</span> only the docker process, not all processes <span class="keyword">in</span> the cgroup</span></span><br><span class="line">KillMode=process</span><br><span class="line"><span class="meta">#</span><span class="bash"> restart the docker process <span class="keyword">if</span> it exits prematurely</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<ul>
<li>dockerd 运行时会调用其它 docker 命令，如 docker-proxy，所以需要将 docker 命令所在的目录加到 PATH 环境变量中</li>
<li>flanneld 启动时将网络配置写入到 <code>/run/flannel/docker</code> 文件中的变量 <code>DOCKER_NETWORK_OPTIONS</code>，dockerd 命令行上指定该变量值来设置 docker0 网桥参数</li>
<li>如果指定了多个 <code>EnvironmentFile</code> 选项，则必须将 <code>/run/flannel/docker</code> 放在最后(确保 docker0 使用 flanneld 生成的 bip 参数)</li>
<li>不能关闭默认开启的 <code>--iptables</code> 和 <code>--ip-masq</code> 选项</li>
<li>如果内核版本比较新，建议使用 <code>overlay</code> 存储驱动</li>
<li>docker 从 1.13 版本开始，可能将 <strong>iptables FORWARD chain的默认策略设置为DROP</strong>，从而导致 ping 其它 Node 上的 Pod IP 失败，遇到这种情况时，需要手动设置策略为 <code>ACCEPT</code>：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure>

<p>如果没有开启上面的路由转发(<code>net.ipv4.ip_forward=1</code>)，则需要把以下命令写入<code>/etc/rc.local</code>文件中，防止节点重启<strong>iptables FORWARD chain的默认策略又还原为DROP</strong>（下面的开机脚本我测试了几次都没生效，不知道是不是方法有误，所以最好的方式还是开启上面的路由转发功能，一劳永逸）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sleep 60 &amp;&amp; /sbin/iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure>

<ul>
<li>为了加快 pull image 的速度，可以使用国内的仓库镜像服务器，同时增加下载的并发数。(如果 dockerd 已经运行，则需要重启 dockerd 生效。)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">  &#123;</span><br><span class="line">    "max-concurrent-downloads": 10</span><br><span class="line">  &#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h3 id="启动docker"><a href="#启动docker" class="headerlink" title="启动docker"></a>启动docker</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl stop firewalld</span><br><span class="line">sudo systemctl disable firewalld</span><br><span class="line">sudo iptables -F &amp;&amp; sudo iptables -X &amp;&amp; sudo iptables -F -t nat &amp;&amp; sudo iptables -X -t nat</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line">sudo systemctl start docker</span><br></pre></td></tr></table></figure>

<ul>
<li>需要关闭 firewalld(centos7)/ufw(ubuntu16.04)，否则可能会重复创建 iptables 规则</li>
<li>最好清理旧的 iptables rules 和 chains 规则</li>
<li>执行命令：docker version，检查docker服务是否正常</li>
</ul>
<h3 id="安装和配置kubelet"><a href="#安装和配置kubelet" class="headerlink" title="安装和配置kubelet"></a>安装和配置kubelet</h3><p>kubelet 启动时向kube-apiserver 发送TLS bootstrapping 请求，需要先将bootstrap token 文件中的kubelet-bootstrap 用户赋予system:node-bootstrapper 角色，然后kubelet 才有权限创建认证请求(certificatesigningrequests)：</p>
<blockquote>
<p>kubelet就是运行在Node节点上的，所以这一步安装是在所有的Node节点上，如果你想把你的Master也当做Node节点的话，当然也可以在Master节点上安装的。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap</span><br></pre></td></tr></table></figure>

<ul>
<li><code>--user=kubelet-bootstrap</code> 是文件 <code>/etc/kubernetes/token.csv</code> 中指定的用户名，同时也写入了文件 <code>/etc/kubernetes/bootstrap.kubeconfig</code></li>
</ul>
<p>另外1.8 版本中还需要为Node 请求创建一个RBAC 授权规则：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding kubelet-nodes --clusterrole=system:node --group=system:nodes</span><br></pre></td></tr></table></figure>

<p>然后下载最新的kubelet 和kube-proxy 二进制文件（前面下载kubernetes 目录下面其实也有）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.k8s.io/v1.8.2/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar -xzvf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">cd kubernetes</span><br><span class="line">tar -xzvf  kubernetes-src.tar.gz</span><br><span class="line">sudo cp -r ./server/bin/&#123;kube-proxy,kubelet&#125; /usr/k8s/bin/</span><br></pre></td></tr></table></figure>

<h3 id="创建kubelet-bootstapping-kubeconfig-文件"><a href="#创建kubelet-bootstapping-kubeconfig-文件" class="headerlink" title="创建kubelet bootstapping kubeconfig 文件"></a>创建kubelet bootstapping kubeconfig 文件</h3><p> 在node执行(node需要bootstrap.kubeconfig文件)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubelet-bootstrap \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span><br><span class="line">mv bootstrap.kubeconfig /etc/kubernetes/</span><br></pre></td></tr></table></figure>

<ul>
<li><code>--embed-certs</code> 为 <code>true</code> 时表示将 <code>certificate-authority</code> 证书写入到生成的 <code>bootstrap.kubeconfig</code> 文件中；</li>
<li>设置 kubelet 客户端认证参数时<strong>没有</strong>指定秘钥和证书，后续由 <code>kube-apiserver</code> 自动生成；</li>
</ul>
<h3 id="创建kubelet-的systemd-unit-文件"><a href="#创建kubelet-的systemd-unit-文件" class="headerlink" title="创建kubelet 的systemd unit 文件"></a>创建kubelet 的systemd unit 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /var/lib/kubelet # 必须先创建工作目录</span><br><span class="line">cat &gt; kubelet.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">ExecStart=/usr/k8s/bin/kubelet \\</span><br><span class="line">  --fail-swap-on=false \\</span><br><span class="line">  --cgroup-driver=cgroupfs \\</span><br><span class="line">  --address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --hostname-override=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --experimental-bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><br><span class="line">  --require-kubeconfig \\</span><br><span class="line">  --cert-dir=/etc/kubernetes/ssl \\</span><br><span class="line">  --cluster-dns=$&#123;CLUSTER_DNS_SVC_IP&#125; \\</span><br><span class="line">  --cluster-domain=$&#123;CLUSTER_DNS_DOMAIN&#125; \\</span><br><span class="line">  --hairpin-mode promiscuous-bridge \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --serialize-image-pulls=false \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>请仔细阅读下面的注意事项，不然可能会启动失败</strong>。</p>
</blockquote>
<ul>
<li><code>--fail-swap-on</code>参数，这个一定要注意，<strong>Kubernetes 1.8开始要求关闭系统的Swap</strong>，如果不关闭，默认配置下kubelet将无法启动，也可以通过kubelet的启动参数<code>–fail-swap-on=false</code>来避免该问题</li>
<li><code>--cgroup-driver</code>参数，kubelet 用来维护主机的的 cgroups 的，默认是<code>cgroupfs</code>，但是这个地方的值需要你根据docker 的配置来确定（<code>docker info |grep cgroup</code>）</li>
<li><code>-address</code> 不能设置为 <code>127.0.0.1</code>，否则后续 Pods 访问 kubelet 的 API 接口时会失败，因为 Pods 访问的 <code>127.0.0.1</code>指向自己而不是 kubelet</li>
<li>如果设置了 <code>--hostname-override</code> 选项，则 <code>kube-proxy</code> 也需要设置该选项，否则会出现找不到 Node 的情况</li>
<li><code>--experimental-bootstrap-kubeconfig</code> 指向 bootstrap kubeconfig 文件，kubelet 使用该文件中的用户名和 token 向 kube-apiserver 发送 TLS Bootstrapping 请求</li>
<li>管理员通过了 CSR 请求后，kubelet 自动在 <code>--cert-dir</code> 目录创建证书和私钥文件(<code>kubelet-client.crt</code> 和 <code>kubelet-client.key</code>)，然后写入 <code>--kubeconfig</code> 文件(自动创建 <code>--kubeconfig</code> 指定的文件)</li>
<li>建议在 <code>--kubeconfig</code> 配置文件中指定 <code>kube-apiserver</code> 地址，如果未指定 <code>--api-servers</code> 选项，则必须指定 <code>--require-kubeconfig</code> 选项后才从配置文件中读取 kue-apiserver 的地址，否则 kubelet 启动后将找不到 kube-apiserver (日志中提示未找到 API Server），<code>kubectl get nodes</code> 不会返回对应的 Node 信息</li>
<li><code>--cluster-dns</code> 指定 kubedns 的 Service IP(可以先分配，后续创建 kubedns 服务时指定该 IP)，<code>--cluster-domain</code> 指定域名后缀，这两个参数同时指定后才会生效</li>
</ul>
<h3 id="启动kubelet"><a href="#启动kubelet" class="headerlink" title="启动kubelet"></a>启动kubelet</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo cp kubelet.service /etc/systemd/system/kubelet.service</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable kubelet</span><br><span class="line">sudo systemctl start kubelet</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure>

<h3 id="通过kubelet-的TLS-证书请求"><a href="#通过kubelet-的TLS-证书请求" class="headerlink" title="通过kubelet 的TLS 证书请求"></a>通过kubelet 的TLS 证书请求</h3><p>有几个node节点就有几个证书请求</p>
<p>kubelet 首次启动时向kube-apiserver 发送证书签名请求，必须通过后kubernetes 系统才会将该 Node 加入到集群。查看未授权的CSR 请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get csr</span><br><span class="line">NAME                                                   AGE       REQUESTOR           CONDITION</span><br><span class="line">node-csr-j6-yJCcqj2wY3AmWh0R13aNwZw-EX3-rnJ1LNYqPlY8   10s       kubelet-bootstrap   Pending</span><br><span class="line">node-csr-kvQwPMrqwy5Xee0VLD8ZtLIHPo2HDBd_XyzL5WLivb4   1m        kubelet-bootstrap   Approved,Issued</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#一个node已经同意</span></span></span><br><span class="line">kubectl get nodes</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>

<p>通过CSR 请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl certificate approve node-csr-j6-yJCcqj2wY3AmWh0R13aNwZw-EX3-rnJ1LNYqPlY8</span><br><span class="line">certificatesigningrequest "node-csr-j6-yJCcqj2wY3AmWh0R13aNwZw-EX3-rnJ1LNYqPlY8" approved</span><br><span class="line">kubectl get nodes</span><br><span class="line">NAME            STATUS    ROLES     AGE       VERSION</span><br><span class="line">192.168.1.170   Ready     &lt;none&gt;    48s       v1.8.9</span><br></pre></td></tr></table></figure>

<p><img src="/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/nodes.png" alt></p>
<p>自动生成了kubelet kubeconfig 文件和公私钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ls -l /etc/kubernetes/kubelet.kubeconfig</span><br><span class="line">-rw------- 1 root root 2280 Nov  7 10:26 /etc/kubernetes/kubelet.kubeconfig</span><br><span class="line">ls -l /etc/kubernetes/ssl/kubelet*</span><br><span class="line">-rw-r--r-- 1 root root 1046 Nov  7 10:26 /etc/kubernetes/ssl/kubelet-client.crt</span><br><span class="line">-rw------- 1 root root  227 Nov  7 10:22 /etc/kubernetes/ssl/kubelet-client.key</span><br><span class="line">-rw-r--r-- 1 root root 1115 Nov  7 10:16 /etc/kubernetes/ssl/kubelet.crt</span><br><span class="line">-rw------- 1 root root 1675 Nov  7 10:16 /etc/kubernetes/ssl/kubelet.key</span><br></pre></td></tr></table></figure>

<h3 id="配置kube-proxy"><a href="#配置kube-proxy" class="headerlink" title="配置kube-proxy"></a>配置kube-proxy</h3><h4 id="创建kube-proxy-证书签名请求："><a href="#创建kube-proxy-证书签名请求：" class="headerlink" title="创建kube-proxy 证书签名请求："></a>创建kube-proxy 证书签名请求：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-proxy",</span><br><span class="line">  "hosts": [],</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "BeiJing",</span><br><span class="line">      "L": "BeiJing",</span><br><span class="line">      "O": "k8s",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li>CN 指定该证书的 User 为 <code>system:kube-proxy</code></li>
<li><code>kube-apiserver</code> 预定义的 RoleBinding <code>system:node-proxier</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code>绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
<li>hosts 属性值为空列表</li>
</ul>
<h4 id="生成kube-proxy-客户端证书和私钥"><a href="#生成kube-proxy-客户端证书和私钥" class="headerlink" title="生成kube-proxy 客户端证书和私钥"></a>生成kube-proxy 客户端证书和私钥</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  -ca-key=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  -config=/etc/kubernetes/ssl/ca-config.json \</span><br><span class="line">  -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line">ls kube-proxy*</span><br><span class="line">kube-proxy.csr  kube-proxy-csr.json  kube-proxy-key.pem  kube-proxy.pem</span><br><span class="line">sudo mv kube-proxy*.pem /etc/kubernetes/ssl/</span><br></pre></td></tr></table></figure>

<h4 id="创建kube-proxy-kubeconfig-文件"><a href="#创建kube-proxy-kubeconfig-文件" class="headerlink" title="创建kube-proxy kubeconfig 文件"></a>创建kube-proxy kubeconfig 文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate=/etc/kubernetes/ssl/kube-proxy.pem \</span><br><span class="line">  --client-key=/etc/kubernetes/ssl/kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line">mv kube-proxy.kubeconfig /etc/kubernetes/</span><br></pre></td></tr></table></figure>

<ul>
<li>设置集群参数和客户端认证参数时 <code>--embed-certs</code> 都为 <code>true</code>，这会将 <code>certificate-authority</code>、<code>client-certificate</code> 和 <code>client-key</code> 指向的证书文件内容写入到生成的 <code>kube-proxy.kubeconfig</code> 文件中</li>
<li><code>kube-proxy.pem</code> 证书中 CN 为 <code>system:kube-proxy</code>，<code>kube-apiserver</code> 预定义的 RoleBinding <code>cluster-admin</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
</ul>
<h4 id="创建kube-proxy-的systemd-unit-文件"><a href="#创建kube-proxy-的systemd-unit-文件" class="headerlink" title="创建kube-proxy 的systemd unit 文件"></a>创建kube-proxy 的systemd unit 文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p /var/lib/kube-proxy # 必须先创建工作目录</span><br><span class="line">cat &gt; kube-proxy.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kube-proxy</span><br><span class="line">ExecStart=/usr/k8s/bin/kube-proxy \\</span><br><span class="line">  --bind-address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --hostname-override=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --cluster-cidr=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>--hostname-override</code> 参数值必须与 kubelet 的值一致，否则 kube-proxy 启动后会找不到该 Node，从而不会创建任何 iptables 规则</li>
<li><code>--cluster-cidr</code> 必须与 kube-apiserver 的 <code>--service-cluster-ip-range</code> 选项值一致</li>
<li>kube-proxy 根据 <code>--cluster-cidr</code> 判断集群内部和外部流量，指定 <code>--cluster-cidr</code> 或 <code>--masquerade-all</code> 选项后 kube-proxy 才会对访问 Service IP 的请求做 SNAT</li>
<li><code>--kubeconfig</code> 指定的配置文件嵌入了 kube-apiserver 的地址、用户名、证书、秘钥等请求和认证信息</li>
<li>预定义的 RoleBinding <code>cluster-admin</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
</ul>
<h4 id="启动kube-proxy"><a href="#启动kube-proxy" class="headerlink" title="启动kube-proxy"></a>启动kube-proxy</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo mv kube-proxy.service /etc/systemd/system/</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl enable kube-proxy</span><br><span class="line">sudo systemctl start kube-proxy</span><br><span class="line">systemctl status kube-proxy</span><br></pre></td></tr></table></figure>

<h3 id="验证集群功能"><a href="#验证集群功能" class="headerlink" title="验证集群功能"></a>验证集群功能</h3><p>定义yaml 文件：（将下面内容保存为：nginx-ds.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">cat</span> <span class="string">&gt;</span> <span class="string">nginx-ds.yaml</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ds</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-ds</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx-ds</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ds</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx-ds</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line"><span class="string">EOF</span></span><br></pre></td></tr></table></figure>

<p>创建 Pod 和服务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f nginx-ds.yaml</span><br><span class="line">service "nginx-ds" created</span><br><span class="line">daemonset "nginx-ds" created</span><br></pre></td></tr></table></figure>

<h3 id="创建失败："><a href="#创建失败：" class="headerlink" title="创建失败："></a>创建失败：</h3><p>describe 出现Failed create pod sandbox.</p>
<p>journalctl -u kubelet -n 100</p>
<p><img src="/2020/02/22/k8s/%E6%89%8B%E5%8A%A8%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84k8s%E9%9B%86%E7%BE%A4/2.png" alt></p>
<p>解决方法如下，从docker.io把pause-amd64镜像取下来，然后做个标签。这样就可以解决问题。</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull googlecontainer/pause-amd64:<span class="number">3.0</span></span><br><span class="line">docker tag googlecontainer/pause-amd64:<span class="number">3.0</span> gcr.io/google_containers/pause-amd64:<span class="number">3.0</span></span><br></pre></td></tr></table></figure>

<p>执行下面的命令查看Pod 和SVC：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br><span class="line">NAME             READY     STATUS    RESTARTS   AGE       IP           NODE</span><br><span class="line">nginx-ds-f29zt   1/1       Running   0          23m       172.17.0.2   192.168.1.170</span><br><span class="line">kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">nginx-ds     NodePort    10.254.6.249   &lt;none&gt;        80:30813/TCP   24m</span><br></pre></td></tr></table></figure>

<p>可以看到：</p>
<ul>
<li>服务IP：10.254.6.249</li>
<li>服务端口：80</li>
<li>NodePort端口：30813</li>
</ul>
<p>在所有 Node 上执行：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl <span class="number">10.254</span><span class="number">.6</span><span class="number">.249</span></span><br><span class="line">$ curl <span class="number">192.168</span><span class="number">.1</span><span class="number">.170</span>:<span class="number">30813</span></span><br></pre></td></tr></table></figure>

<p>执行上面的命令预期都会输出nginx 欢迎页面内容，表示我们的Node 节点正常运行了。</p>
<p>​    </p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/k8s/" <i class="fa fa-tag"></i>k8s</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/21/docker/docker/" rel="prev" title="Docker简介">
      <i class="fa fa-chevron-left"></i> Docker简介
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/02/26/Nginx/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/" rel="next" title="Nginx反向代理">
      Nginx反向代理 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
      
      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-组件版本-amp-amp-集群环境"><span class="nav-number">1.</span> <span class="nav-text">1. 组件版本 &amp;&amp; 集群环境</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#组件版本"><span class="nav-number">1.0.1.</span> <span class="nav-text">组件版本</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-集群-amp-amp-k8s-master-机器-amp-amp-k8s-node-机器"><span class="nav-number">1.0.2.</span> <span class="nav-text">etcd 集群 &amp;&amp; k8s master 机器 &amp;&amp; k8s node 机器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#工作目录"><span class="nav-number">1.0.3.</span> <span class="nav-text">工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集群环境变量"><span class="nav-number">1.0.4.</span> <span class="nav-text">集群环境变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-创建CA-证书和密钥"><span class="nav-number">1.1.</span> <span class="nav-text">2. 创建CA 证书和密钥</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装-CFSSL"><span class="nav-number">1.1.1.</span> <span class="nav-text">安装 CFSSL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建CA"><span class="nav-number">1.1.2.</span> <span class="nav-text">创建CA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分发证书"><span class="nav-number">1.1.3.</span> <span class="nav-text">分发证书</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-部署高可用etcd-集群"><span class="nav-number">1.2.</span> <span class="nav-text">3. 部署高可用etcd 集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#三个节点重复–-gt"><span class="nav-number">1.2.1.</span> <span class="nav-text">三个节点重复–&gt;</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定义环境变量"><span class="nav-number">1.2.2.</span> <span class="nav-text">定义环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下载etcd-二进制文件"><span class="nav-number">1.2.3.</span> <span class="nav-text">下载etcd 二进制文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建TLS-密钥和证书"><span class="nav-number">1.2.4.</span> <span class="nav-text">创建TLS 密钥和证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建etcd-的systemd-unit-文件"><span class="nav-number">1.2.5.</span> <span class="nav-text">创建etcd 的systemd unit 文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动etcd-服务"><span class="nav-number">1.2.6.</span> <span class="nav-text">启动etcd 服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证服务"><span class="nav-number">1.2.7.</span> <span class="nav-text">验证服务</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-配置kubectl-命令行工具"><span class="nav-number">1.3.</span> <span class="nav-text">4. 配置kubectl 命令行工具</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#环境变量"><span class="nav-number">1.3.1.</span> <span class="nav-text">环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下载kubectl"><span class="nav-number">1.3.2.</span> <span class="nav-text">下载kubectl</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建admin-证书"><span class="nav-number">1.3.3.</span> <span class="nav-text">创建admin 证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kubectl-kubeconfig-文件"><span class="nav-number">1.3.4.</span> <span class="nav-text">创建kubectl kubeconfig 文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分发kubeconfig-文件"><span class="nav-number">1.3.5.</span> <span class="nav-text">分发kubeconfig 文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-部署Flannel-网络"><span class="nav-number">1.4.</span> <span class="nav-text">5. 部署Flannel 网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#环境变量-1"><span class="nav-number">1.4.1.</span> <span class="nav-text">环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建TLS-密钥和证书-1"><span class="nav-number">1.4.2.</span> <span class="nav-text">创建TLS 密钥和证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#向etcd-写入集群Pod-网段信息"><span class="nav-number">1.4.3.</span> <span class="nav-text">向etcd 写入集群Pod 网段信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装和配置flanneld"><span class="nav-number">1.4.4.</span> <span class="nav-text">安装和配置flanneld</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动flanneld"><span class="nav-number">1.4.5.</span> <span class="nav-text">启动flanneld</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检查flanneld-服务"><span class="nav-number">1.4.6.</span> <span class="nav-text">检查flanneld 服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检查分配给各flanneld-的Pod-网段信息"><span class="nav-number">1.4.7.</span> <span class="nav-text">检查分配给各flanneld 的Pod 网段信息</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#确保各节点间Pod-网段能互联互通"><span class="nav-number">1.4.8.</span> <span class="nav-text">确保各节点间Pod 网段能互联互通</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-部署master-节点"><span class="nav-number">1.5.</span> <span class="nav-text">6. 部署master 节点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#环境变量-2"><span class="nav-number">1.5.1.</span> <span class="nav-text">环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下载最新版本的二进制文件"><span class="nav-number">1.5.2.</span> <span class="nav-text">下载最新版本的二进制文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kubernetes-证书-以下master机器都要做"><span class="nav-number">1.5.3.</span> <span class="nav-text">创建kubernetes 证书 #以下master机器都要做</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-1-配置和启动kube-apiserver"><span class="nav-number">1.5.4.</span> <span class="nav-text">6.1 配置和启动kube-apiserver</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-apiserver-使用的客户端token-文件"><span class="nav-number">1.5.4.1.</span> <span class="nav-text">创建kube-apiserver 使用的客户端token 文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-apiserver-的systemd-unit文件"><span class="nav-number">1.5.4.2.</span> <span class="nav-text">创建kube-apiserver 的systemd unit文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动kube-apiserver"><span class="nav-number">1.5.4.3.</span> <span class="nav-text">启动kube-apiserver</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-2-配置和启动kube-controller-manager"><span class="nav-number">1.5.5.</span> <span class="nav-text">6.2 配置和启动kube-controller-manager</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-controller-manager-的systemd-unit-文件"><span class="nav-number">1.5.5.1.</span> <span class="nav-text">创建kube-controller-manager 的systemd unit 文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动kube-controller-manager"><span class="nav-number">1.5.5.2.</span> <span class="nav-text">启动kube-controller-manager</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-3-配置和启动kube-scheduler"><span class="nav-number">1.5.6.</span> <span class="nav-text">6.3 配置和启动kube-scheduler</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-scheduler-的systemd-unit文件"><span class="nav-number">1.5.6.1.</span> <span class="nav-text">创建kube-scheduler 的systemd unit文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动kube-scheduler"><span class="nav-number">1.5.6.2.</span> <span class="nav-text">启动kube-scheduler</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-4-验证master-节点"><span class="nav-number">1.5.7.</span> <span class="nav-text">6.4 验证master 节点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-kube-apiserver-高可用"><span class="nav-number">1.6.</span> <span class="nav-text">7. kube-apiserver 高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装haproxy"><span class="nav-number">1.6.1.</span> <span class="nav-text">安装haproxy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置haproxy"><span class="nav-number">1.6.2.</span> <span class="nav-text">配置haproxy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动haproxy"><span class="nav-number">1.6.3.</span> <span class="nav-text">启动haproxy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#问题"><span class="nav-number">1.6.4.</span> <span class="nav-text">问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#方式1：使用阿里云SLB"><span class="nav-number">1.6.4.1.</span> <span class="nav-text">方式1：使用阿里云SLB</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#方式2：使用keepalived"><span class="nav-number">1.6.4.2.</span> <span class="nav-text">方式2：使用keepalived</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-controller-manager-和kube-scheduler-的高可用"><span class="nav-number">1.6.5.</span> <span class="nav-text">kube-controller-manager 和kube-scheduler 的高可用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-部署Node-节点"><span class="nav-number">1.7.</span> <span class="nav-text">8. 部署Node 节点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#环境变量-3"><span class="nav-number">1.7.1.</span> <span class="nav-text">环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#开启路由转发"><span class="nav-number">1.7.2.</span> <span class="nav-text">开启路由转发</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置docker"><span class="nav-number">1.7.3.</span> <span class="nav-text">配置docker</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动docker"><span class="nav-number">1.7.4.</span> <span class="nav-text">启动docker</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装和配置kubelet"><span class="nav-number">1.7.5.</span> <span class="nav-text">安装和配置kubelet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kubelet-bootstapping-kubeconfig-文件"><span class="nav-number">1.7.6.</span> <span class="nav-text">创建kubelet bootstapping kubeconfig 文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kubelet-的systemd-unit-文件"><span class="nav-number">1.7.7.</span> <span class="nav-text">创建kubelet 的systemd unit 文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动kubelet"><span class="nav-number">1.7.8.</span> <span class="nav-text">启动kubelet</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#通过kubelet-的TLS-证书请求"><span class="nav-number">1.7.9.</span> <span class="nav-text">通过kubelet 的TLS 证书请求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置kube-proxy"><span class="nav-number">1.7.10.</span> <span class="nav-text">配置kube-proxy</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-proxy-证书签名请求："><span class="nav-number">1.7.10.1.</span> <span class="nav-text">创建kube-proxy 证书签名请求：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#生成kube-proxy-客户端证书和私钥"><span class="nav-number">1.7.10.2.</span> <span class="nav-text">生成kube-proxy 客户端证书和私钥</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-proxy-kubeconfig-文件"><span class="nav-number">1.7.10.3.</span> <span class="nav-text">创建kube-proxy kubeconfig 文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建kube-proxy-的systemd-unit-文件"><span class="nav-number">1.7.10.4.</span> <span class="nav-text">创建kube-proxy 的systemd unit 文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#启动kube-proxy"><span class="nav-number">1.7.10.5.</span> <span class="nav-text">启动kube-proxy</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证集群功能"><span class="nav-number">1.7.11.</span> <span class="nav-text">验证集群功能</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建失败："><span class="nav-number">1.7.12.</span> <span class="nav-text">创建失败：</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">屈辉</p>
  <div class="site-description" itemprop="description">开心就好</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">115</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">59</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">屈辉</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.7.1
  </div> -->

        








      </div>
    </footer>
  </div>

  
  
  <script color='3423,34,234' opacity='0.35' zIndex='-1' count='150' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
